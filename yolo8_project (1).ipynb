{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a53e2c-05e0-4586-85e4-d8afe336984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1\n",
      "Uninstalling torch-2.5.1:\n",
      "  Successfully uninstalled torch-2.5.1\n",
      "Found existing installation: torchvision 0.20.1\n",
      "Uninstalling torchvision-0.20.1:\n",
      "  Successfully uninstalled torchvision-0.20.1\n",
      "Found existing installation: torchaudio 2.5.1\n",
      "Uninstalling torchaudio-2.5.1:\n",
      "  Successfully uninstalled torchaudio-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dd03d7-bc85-442d-98f5-f06b2839ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.5.1-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "Using cached torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Using cached torchaudio-2.5.1-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8024b44-6171-462a-8d78-ccb95f93b2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (8.3.27)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul-pc\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f6a273-4306-4d6c-b984-921aba771d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee362da-ceb5-434a-9584-3e33cc80d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telegram bot setup\n",
    "TELEGRAM_BOT_TOKEN = '7797273300:AAEt21FaUKyc4seiHFLf1p3eNnHWuc72nnM'\n",
    "TELEGRAM_CHAT_ID = '5830227450'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a48a07-88bd-4346-ba9b-e7dfd332d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location():\n",
    "    \"\"\"Fetch the current location based on IP address using ipinfo.io.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        loc = data.get(\"loc\")\n",
    "        if loc:\n",
    "            latitude, longitude = map(float, loc.split(','))\n",
    "            print(f\"Current Location: Latitude={latitude}, Longitude={longitude}\")\n",
    "            return latitude, longitude\n",
    "        else:\n",
    "            print(\"Location information not available.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching location: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b33493c-eed3-4286-a568-26a221ea3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_location_to_telegram():\n",
    "    latitude, longitude = get_location()\n",
    "    if latitude and longitude:\n",
    "        token = '7797273300:AAEt21FaUKyc4seiHFLf1p3eNnHWuc72nnM'\n",
    "        chat_id = '5830227450'\n",
    "        url = f'https://api.telegram.org/bot{token}/sendLocation'\n",
    "        response = requests.post(url, data={\n",
    "            'chat_id': chat_id,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude\n",
    "        })\n",
    "        if response.status_code == 200:\n",
    "            print(\"Location sent successfully!\")\n",
    "        else:\n",
    "            print(\"Failed to send location:\", response.json())\n",
    "    else:\n",
    "        print(\"Could not fetch location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09cb18c9-b67f-4d4a-b0f6-8040b6831924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_telegram_alert(image_path, detected_objects):\n",
    "    \"\"\"Send a warning message and both original and black-and-white images to Telegram\"\"\"\n",
    "\n",
    "    detected_objects_str = ''.join(detected_objects)\n",
    "    message = f\"Alert! Detected objects: {detected_objects_str}\"\n",
    "    \n",
    "    # Corrected URLs with both bot token and chat ID\n",
    "    bot_token = \"7797273300:AAEt21FaUKyc4seiHFLf1p3eNnHWuc72nnM\"\n",
    "    chat_id = \"5830227450\"\n",
    "    text_url = f'https://api.telegram.org/bot7797273300:AAEt21FaUKyc4seiHFLf1p3eNnHWuc72nnM/sendMessage'\n",
    "    photo_url = f'https://api.telegram.org/bot7797273300:AAEt21FaUKyc4seiHFLf1p3eNnHWuc72nnM/sendPhoto'\n",
    "\n",
    "    # Send text message\n",
    "    requests.post(text_url, data={'chat_id': 5830227450, 'text': message})\n",
    "    \n",
    "    # Read the original image\n",
    "    original_image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to high-quality black-and-white (grayscale with contrast enhancement)\n",
    "    gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    high_quality_bw = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    # Save the black-and-white version temporarily\n",
    "    bw_image_path = \"high_quality_bw.jpg\"\n",
    "    cv2.imwrite(bw_image_path, high_quality_bw)\n",
    "\n",
    "    \n",
    "    # Send original image to Telegram\n",
    "    with open(image_path, 'rb') as img:\n",
    "        requests.post(photo_url, data={'chat_id': 5830227450, 'caption': \"Original Image\"}, files={'photo': img})\n",
    "    \n",
    "    # Send black-and-white image to Telegram\n",
    "    with open(bw_image_path, 'rb') as bw_img:\n",
    "        requests.post(photo_url, data={'chat_id': 5830227450, 'caption': \"High-Quality Black and White Image\"}, files={'photo': bw_img})\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ddbae68-bd81-476e-a874-c8b0a603b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c61c86e-7547-4271-b29c-90eb40c54e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\",\"toy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7226ec9b-0842-430b-9766-6b21969d66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects():\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    detected = set()  \n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model(frame,conf=0.8)\n",
    "        current_detections = set()  # Store current detections for this frame\n",
    "        \n",
    "        # Iterate through the detected results\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Get the boxes from the result\n",
    "            for box in boxes:  # Loop through each box\n",
    "                label = int(box.cls.item())  # Convert class ID tensor to int\n",
    "                confidence = box.conf.item()  # Convert confidence tensor to float\n",
    "                if confidence > 0.5:  # Consider only detections with confidence > 0.5\n",
    "                    detected_object = classNames[label]\n",
    "                    current_detections.add(detected_object)  # Add the detected class name\n",
    "                    \n",
    "                    # Draw bounding boxes on frame\n",
    "                    x1, y1, x2, y2 = box.xyxy.numpy()[0]  # Get the bounding box coordinates\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame, f\"{detected_object}: {confidence:.2f}\", \n",
    "                                (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "                    # Check if the object is newly detected\n",
    "                    if detected_object not in detected:\n",
    "                        # Save frame with detection and send to Telegram\n",
    "                        cv2.imwrite(f\"{detected_object}_detected.jpg\", frame)\n",
    "                        send_telegram_alert(f\"{detected_object}_detected.jpg\", detected_object)\n",
    "                        send_location_to_telegram()\n",
    "                        detected.add(detected_object)  # Update detected set\n",
    "        cv2.imshow(\"Object Detection\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44e92a66-09f3-434e-855d-8951a737ba6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 200.2ms\n",
      "Speed: 10.0ms preprocess, 200.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Current Location: Latitude=25.5941, Longitude=85.1356\n",
      "Location sent successfully!\n",
      "\n",
      "0: 480x640 1 person, 221.1ms\n",
      "Speed: 3.0ms preprocess, 221.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.4ms\n",
      "Speed: 5.0ms preprocess, 213.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.0ms\n",
      "Speed: 6.1ms preprocess, 223.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 215.1ms\n",
      "Speed: 5.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 292.7ms\n",
      "Speed: 5.0ms preprocess, 292.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 322.6ms\n",
      "Speed: 5.0ms preprocess, 322.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 302.1ms\n",
      "Speed: 15.0ms preprocess, 302.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 211.1ms\n",
      "Speed: 6.0ms preprocess, 211.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.2ms\n",
      "Speed: 7.0ms preprocess, 223.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.1ms\n",
      "Speed: 5.0ms preprocess, 209.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 250.2ms\n",
      "Speed: 7.0ms preprocess, 250.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.6ms\n",
      "Speed: 4.0ms preprocess, 222.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.6ms\n",
      "Speed: 4.0ms preprocess, 208.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.1ms\n",
      "Speed: 4.0ms preprocess, 199.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 271.4ms\n",
      "Speed: 5.6ms preprocess, 271.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 228.1ms\n",
      "Speed: 6.5ms preprocess, 228.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 211.1ms\n",
      "Speed: 5.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 215.2ms\n",
      "Speed: 4.0ms preprocess, 215.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 212.6ms\n",
      "Speed: 5.0ms preprocess, 212.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 204.5ms\n",
      "Speed: 4.0ms preprocess, 204.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 217.1ms\n",
      "Speed: 5.0ms preprocess, 217.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 246.8ms\n",
      "Speed: 6.0ms preprocess, 246.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.1ms\n",
      "Speed: 4.6ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 201.0ms\n",
      "Speed: 5.0ms preprocess, 201.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 213.2ms\n",
      "Speed: 8.0ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 14.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.1ms\n",
      "Speed: 3.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.2ms\n",
      "Speed: 6.0ms preprocess, 210.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 198.1ms\n",
      "Speed: 3.0ms preprocess, 198.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.3ms\n",
      "Speed: 4.0ms preprocess, 207.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 204.1ms\n",
      "Speed: 6.0ms preprocess, 204.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 215.6ms\n",
      "Speed: 4.0ms preprocess, 215.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 220.1ms\n",
      "Speed: 5.0ms preprocess, 220.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.6ms\n",
      "Speed: 6.0ms preprocess, 212.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 208.6ms\n",
      "Speed: 5.0ms preprocess, 208.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 187.1ms\n",
      "Speed: 7.0ms preprocess, 187.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 197.8ms\n",
      "Speed: 4.0ms preprocess, 197.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 203.2ms\n",
      "Speed: 5.0ms preprocess, 203.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 208.9ms\n",
      "Speed: 5.0ms preprocess, 208.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 181.1ms\n",
      "Speed: 4.0ms preprocess, 181.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 196.2ms\n",
      "Speed: 6.2ms preprocess, 196.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.2ms\n",
      "Speed: 5.0ms preprocess, 209.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.2ms\n",
      "Speed: 6.0ms preprocess, 217.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.6ms\n",
      "Speed: 5.0ms preprocess, 206.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.1ms\n",
      "Speed: 5.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 204.6ms\n",
      "Speed: 6.0ms preprocess, 204.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 211.1ms\n",
      "Speed: 6.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 211.8ms\n",
      "Speed: 8.0ms preprocess, 211.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Current Location: Latitude=25.5941, Longitude=85.1356\n",
      "Location sent successfully!\n",
      "\n",
      "0: 480x640 (no detections), 185.6ms\n",
      "Speed: 6.6ms preprocess, 185.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.3ms\n",
      "Speed: 3.0ms preprocess, 205.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.2ms\n",
      "Speed: 6.0ms preprocess, 210.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.2ms\n",
      "Speed: 4.0ms preprocess, 212.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.2ms\n",
      "Speed: 4.0ms preprocess, 209.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.8ms\n",
      "Speed: 8.0ms preprocess, 213.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 224.1ms\n",
      "Speed: 4.0ms preprocess, 224.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 218.1ms\n",
      "Speed: 8.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.1ms\n",
      "Speed: 6.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.8ms\n",
      "Speed: 4.6ms preprocess, 199.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.7ms\n",
      "Speed: 5.0ms preprocess, 208.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.9ms\n",
      "Speed: 3.5ms preprocess, 217.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 227.8ms\n",
      "Speed: 5.0ms preprocess, 227.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 218.1ms\n",
      "Speed: 4.5ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.1ms\n",
      "Speed: 6.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 227.0ms\n",
      "Speed: 5.0ms preprocess, 227.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.2ms\n",
      "Speed: 4.0ms preprocess, 202.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.0ms\n",
      "Speed: 5.0ms preprocess, 202.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.6ms\n",
      "Speed: 4.0ms preprocess, 202.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 217.2ms\n",
      "Speed: 6.0ms preprocess, 217.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 195.9ms\n",
      "Speed: 3.0ms preprocess, 195.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 196.1ms\n",
      "Speed: 4.0ms preprocess, 196.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.3ms\n",
      "Speed: 4.5ms preprocess, 210.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.4ms\n",
      "Speed: 5.0ms preprocess, 195.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.9ms\n",
      "Speed: 6.0ms preprocess, 210.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 232.4ms\n",
      "Speed: 4.0ms preprocess, 232.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.9ms\n",
      "Speed: 6.0ms preprocess, 212.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 204.1ms\n",
      "Speed: 4.5ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 187.1ms\n",
      "Speed: 4.0ms preprocess, 187.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.0ms\n",
      "Speed: 6.0ms preprocess, 223.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 216.4ms\n",
      "Speed: 5.0ms preprocess, 216.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 203.1ms\n",
      "Speed: 3.0ms preprocess, 203.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 186.1ms\n",
      "Speed: 4.0ms preprocess, 186.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 202.5ms\n",
      "Speed: 4.5ms preprocess, 202.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.1ms\n",
      "Speed: 6.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 213.6ms\n",
      "Speed: 5.0ms preprocess, 213.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.1ms\n",
      "Speed: 5.5ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.8ms\n",
      "Speed: 5.0ms preprocess, 179.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 195.3ms\n",
      "Speed: 6.0ms preprocess, 195.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.8ms\n",
      "Speed: 4.0ms preprocess, 226.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.1ms\n",
      "Speed: 5.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 199.2ms\n",
      "Speed: 6.6ms preprocess, 199.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 230.2ms\n",
      "Speed: 5.0ms preprocess, 230.2ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Current Location: Latitude=25.5941, Longitude=85.1356\n",
      "Location sent successfully!\n",
      "\n",
      "0: 480x640 (no detections), 227.2ms\n",
      "Speed: 5.1ms preprocess, 227.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.7ms\n",
      "Speed: 6.0ms preprocess, 230.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 232.2ms\n",
      "Speed: 7.0ms preprocess, 232.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 222.1ms\n",
      "Speed: 7.0ms preprocess, 222.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 193.1ms\n",
      "Speed: 5.0ms preprocess, 193.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 225.1ms\n",
      "Speed: 7.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 231.7ms\n",
      "Speed: 4.0ms preprocess, 231.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 213.2ms\n",
      "Speed: 4.0ms preprocess, 213.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.1ms\n",
      "Speed: 7.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.3ms\n",
      "Speed: 4.0ms preprocess, 182.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.5ms\n",
      "Speed: 4.0ms preprocess, 206.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.1ms\n",
      "Speed: 6.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.8ms\n",
      "Speed: 6.0ms preprocess, 205.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.1ms\n",
      "Speed: 6.0ms preprocess, 185.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.3ms\n",
      "Speed: 5.0ms preprocess, 202.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 207.6ms\n",
      "Speed: 4.0ms preprocess, 207.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 201.1ms\n",
      "Speed: 4.0ms preprocess, 201.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 212.1ms\n",
      "Speed: 7.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.7ms\n",
      "Speed: 4.0ms preprocess, 199.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.3ms\n",
      "Speed: 5.0ms preprocess, 209.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 214.1ms\n",
      "Speed: 7.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 193.1ms\n",
      "Speed: 4.0ms preprocess, 193.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 196.6ms\n",
      "Speed: 3.5ms preprocess, 196.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 203.6ms\n",
      "Speed: 4.0ms preprocess, 203.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 205.7ms\n",
      "Speed: 5.0ms preprocess, 205.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 233.3ms\n",
      "Speed: 6.0ms preprocess, 233.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.1ms\n",
      "Speed: 3.0ms preprocess, 202.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 200.1ms\n",
      "Speed: 4.0ms preprocess, 200.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 211.9ms\n",
      "Speed: 5.0ms preprocess, 211.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    detect_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e48395-8c6e-45b0-be45-001ec9194750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d50a8e-48f2-4d37-83f7-84b23d52d86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac06266-21da-4b5c-9227-a8779096c5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c03fe0-bb46-402e-925e-d88e5f1988cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503a58f-5fc5-4fae-8ca1-23f87663e905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
